import os
# === ğŸŒŸ é‡å° Gemini æ¨¡å‹çš„å°å…¥ (ä½¿ç”¨ google-generativeai å¥—ä»¶) ğŸŒŸ ===
import google.generativeai as gemini_genai # çµ¦å®ƒä¸€å€‹åˆ¥å gemini_genai
from google.generativeai import types as gemini_types # çµ¦å®ƒä¸€å€‹åˆ¥å gemini_types

# === ğŸŒŸ é‡å° Gradio Client çš„å°å…¥ ğŸŒŸ ===
from gradio_client import Client # å°å…¥ Gradio Client
# from gradio_client import utils # utils å¦‚æœæ²’æœ‰ç”¨åˆ°å¯ä»¥ä¸å°å…¥ï¼Œç²¾ç°¡ç¨‹å¼ç¢¼

from PIL import Image # åœ–ç‰‡è™•ç†åº«
from io import BytesIO
import asyncio
import logging
from datetime import datetime
from typing import Union

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ API Keys
GEMINI_API_KEY_2 = os.getenv('GEMINI_API_KEY_2') # é€™æ˜¯ä½ åœ¨ .env è£¡è¨­å®šçš„ Gemini API Key

# === ğŸŒŸ æ–°å¢ï¼šè¼‰å…¥ Hugging Face API Key ğŸŒŸ ===
HF_TOKEN = os.getenv("ANYTHING_API_KEY") # å¾ç’°å¢ƒè®Šæ•¸è®€å– HF Token

# ----------------------------------------------------
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ----------------------------------------------------
gemini_model = None
if GEMINI_API_KEY_2:
    gemini_genai.configure(api_key=GEMINI_API_KEY_2) # ç”¨ gemini_genai ä¾†é…ç½®
    gemini_model = gemini_genai.GenerativeModel('gemini-1.5-flash-latest')
    logging.info("Gemini æ¨¡å‹å·²æˆåŠŸåˆå§‹åŒ–ã€‚")
else:
    logging.error("GEMINI_API_KEY_2 æœªè¨­å®šï¼Œç„¡æ³•ä½¿ç”¨ Gemini APIã€‚")


gradio_client_instance = None
GRADIO_SPACE_ID = "Asahina2K/animagine-xl-4.0"

if HF_TOKEN:
    try:
        gradio_client_instance = Client(GRADIO_SPACE_ID, hf_token=HF_TOKEN)
        logging.info(f"Gradio Client å·²æˆåŠŸåˆå§‹åŒ–ä¸¦é€£æ¥åˆ° Space: {GRADIO_SPACE_ID}")
        # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨é€™è£¡æ‰“å° client.view_api() ä¾†æŸ¥çœ‹è©² Space çš„ API ç°½å
        # logging.info(gradio_client_instance.view_api())
    except Exception as e:
        logging.error(f"åˆå§‹åŒ– Gradio Client æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        logging.error("è«‹ç¢ºèª 'gradio_client' å¥—ä»¶å·²æ­£ç¢ºå®‰è£ï¼Œä¸¦ä¸” HUGGING_FACE_API_KEY æœ‰æ•ˆã€‚")
        gradio_client_instance = None
else:
    logging.error("HUGGING_FACE_API_KEY æœªè¨­å®šï¼Œç„¡æ³•åˆå§‹åŒ– Gradio Clientã€‚")


# é è¨­çš„é¢¨æ ¼æç¤ºè©å’Œæœè£æç¤ºè©
specific_style_prompt_loli = (
    "A cute little anime girl with long, flowing white hair, cat ears and tail, "
    "She has amber eyes and a gentle expression."
    
    "Anime style, close-up shot, detailed textures, soft lighting"
    "The scene is soft, warm, and inviting, with gentle sunlight illuminating the scene, emphasizing her soft white hair and dress"
    "soft scene , anime style, detailed textures, soft lighting"
    "the scene should contain  the whole face so that ear is visible"
)

specific_style_prompt_sexy = (
    "A sexy and pretty anime girl with long, flowing white hair, cat ears and tail, "
    "She has amber eyes and a gentle expression."
    "She wears sexily emphasizing her curves and femininity."
    "She is with big boobs"
    "Anime style, close-up shot, detailed textures, soft lighting"
    "The scene is soft, warm, and inviting, with gentle sunlight illuminating the scene, emphasizing her soft white hair and dress"
    "soft scene , anime style, detailed textures, soft lighting"
    "the scene should contain  the whole face so that ear is visible"
)



outfit_prompt = "she wears a white dress with a black sailor-style collar and a black bow at the chest."


async def generate_image_with_ai(conversation_history: str, mode: str, way : str , image_name: str = "generated_image") -> Union[BytesIO, None]:
    """
    æ ¹æ“šå°è©±å…§å®¹å’ŒæŒ‡å®šé¢¨æ ¼ï¼Œå…ˆç”± Gemini ç”Ÿæˆåœ–ç‰‡ Promptï¼Œå†ç”± Hugging Face Gradio Client ç”Ÿæˆåœ–ç‰‡ã€‚
    åœ–ç‰‡å°‡ä»¥ BytesIO ç‰©ä»¶çš„å½¢å¼è¿”å›ã€‚
    """
    # æª¢æŸ¥ Gemini æ¨¡å‹æ˜¯å¦å°±ç·’
    if not gemini_model:
        logging.error("Gemini æ¨¡å‹æœªæ­£ç¢ºåˆå§‹åŒ–ï¼Œç„¡æ³•ç”Ÿæˆåœ–ç‰‡æç¤ºè©ã€‚")
        return None
    
    # æª¢æŸ¥ Gradio Client æ˜¯å¦å°±ç·’
    if not gradio_client_instance:
        logging.error("Gradio Client æœªæ­£ç¢ºåˆå§‹åŒ–ï¼Œç„¡æ³•ç”Ÿæˆåœ–ç‰‡ã€‚")
        return None

    # æ­¥é©Ÿ 1: ä½¿ç”¨ Gemini ç”Ÿæˆ Gradio æ¨¡å‹çš„ Prompt
    try:
        logging.info("æ­£åœ¨ä½¿ç”¨ Gemini ç”Ÿæˆåœ–ç‰‡æç¤ºè© (Prompt)...")
        specific_style_prompt = specific_style_prompt_loli if mode == "loli" else specific_style_prompt_sexy
        specific_style_prompt += " " + outfit_prompt  # æ·»åŠ æœè£æç¤ºè©

        # ç‚º Gradio æ¨¡å‹çš„ prompt æº–å‚™æ›´è©³ç´°çš„æŒ‡ä»¤
        gemini_prompt_text = (
            "ä½ è¦ç”Ÿæˆçš„æ˜¯ä¸€ä½æ“¬äººçš„å¯æ„›è²“å¨˜ä»¥åŠç”¨æˆ¶ä¹‹é–“çš„å°è©±ï¼Œ"
            f"ä»¥ä¸‹æ˜¯æˆ‘å€‘çš„å°è©±å…§å®¹ï¼Œè«‹å°‡å…¶è½‰æ›ç‚ºå¥½çœ‹çš„ç•«é¢ï¼Œä¸ç”¨å®Œå…¨å‘ˆç¾å°è©±å…§å®¹ï¼š\n\n"
            f"\"\"\"{conversation_history}\"\"\"\n\n"
            f"è«‹æ ¹æ“šä¸Šè¿°å°è©±å…§å®¹ï¼Œä¸¦çµåˆä»¥ä¸‹åœ–ç‰‡å¤–è§€å’Œé¢¨æ ¼æç¤ºè©ï¼Œç”Ÿæˆä¸€å€‹ç”¨æ–¼åœ–åƒç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚ Animagine XL 4.0ï¼‰çš„å…·é«”ã€è©³ç´°ã€ä¸”å¯Œæœ‰å‰µæ„çš„è‹±æ–‡æç¤ºè© (Prompt)ã€‚é€™å€‹æç¤ºè©æ‡‰è©²æè¿°ä¸€å€‹åŒ…å«ä»¥ä¸‹å…ƒç´ ï¼Œä¸¦å…·å‚™ä»¥ä¸‹é¢¨æ ¼çš„å ´æ™¯å’Œå‹•ä½œï¼š"
            f"åœ–ç‰‡å¤–è§€å’Œé¢¨æ ¼æç¤ºè©ï¼š\n"
            f"\"\"\"{specific_style_prompt}\"\"\"\n\n"
            f"è«‹ç¢ºä¿ç”Ÿæˆçš„æç¤ºè©èƒ½å¤ æ˜ç¢ºè¡¨é”åœ–ç‰‡çš„ä¸»é¡Œã€äººç‰©å‹•ä½œã€æƒ…ç·’ã€èƒŒæ™¯ç´°ç¯€ã€å…‰ç·šæ°›åœç­‰ã€‚è«‹ç›´æ¥çµ¦å‡ºæç¤ºè©ï¼Œä¸è¦åŒ…å«ä»»ä½•é¡å¤–çš„èªªæ˜æ€§æ–‡å­—ã€‚"
            "ç”Ÿæˆ**è‹±æ–‡çš„ã€é€—è™Ÿåˆ†éš”çš„ã€é©ç”¨æ–¼äºŒæ¬¡å…ƒç¾å°‘å¥³é¢¨æ ¼åœ–ç‰‡ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚Stable Diffusionï¼‰çš„é—œéµè©åˆ—è¡¨ï¼ˆtagsï¼‰**ã€‚"
            "è«‹ç¢ºä¿æç¤ºè©åŒ…å«äººç‰©ã€æœè£ã€å ´æ™¯ã€è¡¨æƒ…ã€å‹•ä½œå’Œæ°›åœçš„è©³ç´°ç´°ç¯€ï¼Œ**ä¸¦ä»¥é«˜è³ªé‡ç¹ªåœ–å¸¸è¦‹çš„é—œéµè©é–‹é ­**ï¼ˆä¾‹å¦‚'masterpiece, best quality, highly detailed'ï¼‰ã€‚**ä¸è¦ä½¿ç”¨å®Œæ•´çš„å¥å­ï¼Œåªæä¾›é—œéµè©å’ŒçŸ­èªã€‚**"
        )
        
        if way != "command" :
            response_parts = await gemini_model.generate_content_async(gemini_prompt_text)
        
        if way == "command" : 
            '''if mode == "loli" :
                gradio_model_prompt = "1girl , young , masterpiece, best quality, highly detailed" + \
                "a cute girl , cat ears and tail, cat , cat "
                " anime style, cute anime , cute " + \
                " long white hair, flowing hair, amber eyes, gentle expression, cute, soft lighting, warm lighting, sunlight, close-up, detailed textures, white dress, black sailor collar, black bow, soft scene"
            if mode == "sexy" :
                gradio_model_prompt = "1girl , masterpiece, best quality, highly detailed" + \
                "a sexy girl , cat ears and tail, " + \
                " anime style, sexy anime , beautiful " + \
                " long white hair, flowing hair, amber eyes, gentle expression, sexy, soft lighting, warm lighting, sunlight, close-up, detailed textures, white dress, black sailor collar, black bow, soft scene"
            gradio_model_prompt += conversation_history
            gradio_model_prompt += " long white hair , cat ears and tail , whole face so that ear is visible" # <--- é€™è£¡åŠ ä¸Šäº† "cat ears and tail , cat ears and tail , whole face so that ear is visible"'''
            response_parts = await gemini_model.generate_content_async(gemini_prompt_text)
        # æª¢æŸ¥ Gemini å›è¦†æ˜¯å¦åŒ…å«å…§å®¹
        
        # æå– Gemini å›è¦†çš„æ–‡å­—å…§å®¹
        
        if hasattr(response_parts.candidates[0].content, 'parts') and response_parts.candidates[0].content.parts:
            gradio_model_prompt = response_parts.candidates[0].content.parts[0].text
        else:
            gradio_model_prompt = response_parts.text
    
        logging.info(f"Gemini ç”Ÿæˆçš„åœ–ç‰‡æç¤ºè©ï¼š\n{gradio_model_prompt}")
        
        
        if not gradio_model_prompt:
            logging.error("Gemini æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åœ–ç‰‡æç¤ºè©ã€‚")
            return None

    except Exception as e:
        logging.error(f"ä½¿ç”¨ Gemini ç”Ÿæˆåœ–ç‰‡æç¤ºè©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

    # æ­¥é©Ÿ 2: ä½¿ç”¨ Gradio Client ç”Ÿæˆåœ–ç‰‡ (çµåˆä½ æœ‹å‹çš„æˆåŠŸç¶“é©—)
    try:
        logging.info(f"æ­£åœ¨ä½¿ç”¨ Gradio Client ({GRADIO_SPACE_ID}) ç”Ÿæˆåœ–ç‰‡...")

        # çµåˆ Gemini ç”Ÿæˆçš„æç¤ºè©å’Œå›ºå®šå“è³ªæ¨™ç±¤
        
        final_gradio_prompt = f"{gradio_model_prompt}, masterpiece, high score, great score, absurdres"
        
        if way == "command" :
            final_gradio_prompt += " , " + conversation_history # <--- é€™è£¡åŠ ä¸Šäº†å°è©±æ­·å²
        final_gradio_prompt += "whole face , ears visibale , cat ears , whole face , whole face so that ear is visible" # <--- é€™è£¡åŠ ä¸Šäº† "cat ears and tail , whole face so that ear is visible"
        final_gradio_prompt = final_gradio_prompt.strip() # <--- åŠ ä¸Šé€™è¡Œï¼
        logging.info(f"æœ€çµ‚ Prompt çš„é•·åº¦ï¼š{len(final_gradio_prompt)}")
        logging.info(f"æœ€çµ‚ Prompt çš„ repr (é¡¯ç¤ºä¸å¯è¦‹å­—å…ƒ): {repr(final_gradio_prompt)}") # <--- æ–°å¢é€™è¡Œï¼
        
        # å›ºå®šè² é¢æç¤ºè© (å¾ä½ æœ‹å‹çš„ç¨‹å¼ç¢¼è¤‡è£½)
        gradio_negative_prompt = "lowres, bad anatomy, bad hands, text, error, missing finger, extra digits, fewer digits, cropped, worst quality, low quality, low score, bad score, average score, signature, watermark, username, blurry"

        # Gradio æ‡‰ç”¨ç¨‹å¼çš„å›ºå®šåƒæ•¸ (å¾ä½ æœ‹å‹çš„ç¨‹å¼ç¢¼è¤‡è£½)
        # é€™äº›åƒæ•¸çš„é †åºå’Œå«ç¾©å¿…é ˆåš´æ ¼æŒ‰ç…§ Gradio æ‡‰ç”¨ç¨‹å¼çš„ /generate å‡½æ•¸å®šç¾©
        seed = 0
        custom_width = 1024
        custom_height = 1024
        guidance_scale = 7.5
        num_inference_steps = 50
        sampler = 'Euler a'
        aspect_ratio_selector = 'Custom'
        style_selector = '(None)'
        use_upscaler = False
        upscaler_strength = 0.55
        upscale_by = 1.5
        add_quality_tags = True
        api_name = "/generate" # é€™å€‹æ˜¯é—œéµï¼ŒæŒ‡å®šè¦èª¿ç”¨ Gradio æ‡‰ç”¨çš„å“ªå€‹å…§éƒ¨å‡½æ•¸
        
        # åœ¨å–®ç¨çš„ç·šç¨‹ä¸­é‹è¡ŒåŒæ­¥çš„ client.predict() å‡½æ•¸
        result = await asyncio.wait_for(
            asyncio.to_thread(gradio_client_instance.predict,
                final_gradio_prompt,       # 1. prompt
                gradio_negative_prompt,    # 2. negative_prompt
                seed,                      # 3. seed
                custom_width,              # 4. custom_width
                custom_height,             # 5. custom_height
                guidance_scale,            # 6. guidance_scale
                num_inference_steps,       # 7. num_inference_steps
                sampler,                   # 8. sampler
                aspect_ratio_selector,     # 9. aspect_ratio_selector
                style_selector,            # 10. style_selector
                use_upscaler,              # 11. use_upscaler
                upscaler_strength,         # 12. upscaler_strength
                upscale_by,                # 13. upscale_by
                add_quality_tags,          # 14. add_quality_tags
                api_name=api_name          # api_name
            ),
            timeout=300 # 5åˆ†é˜è¶…æ™‚
        )

        # æ ¹æ“šä½ æœ‹å‹ç¨‹å¼ç¢¼çš„ç¶“é©—ï¼Œçµæœæ˜¯ä¸€å€‹ tupleï¼Œç¬¬ä¸€å€‹å…ƒç´ æ˜¯åœ–ç‰‡åˆ—è¡¨
        generated_images_list = result[0] 

        if generated_images_list and len(generated_images_list) > 0 and 'image' in generated_images_list[0]:
            # Gradio Client åœ¨ predict æˆåŠŸå¾Œæœƒå°‡åœ–ç‰‡ä¸‹è¼‰åˆ°æœ¬åœ°è‡¨æ™‚æ–‡ä»¶
            image_path_from_client = generated_images_list[0]['image']
            logging.info(f"åœ–ç‰‡å·²åœ¨ Gradio Space ç”Ÿæˆï¼Œä¸¦ä¸‹è¼‰åˆ°è‡¨æ™‚è·¯å¾‘: {image_path_from_client}")

            if isinstance(image_path_from_client, str) and os.path.exists(image_path_from_client):
                with open(image_path_from_client, 'rb') as f:
                    image_bytes = f.read()
                os.remove(image_path_from_client) # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            else:
                raise ValueError(f"Gradio Client è¿”å›çš„åœ–ç‰‡æ•¸æ“šæ ¼å¼ç„¡æ³•è­˜åˆ¥æˆ–æª”æ¡ˆä¸å­˜åœ¨: {image_path_from_client}")

            image_stream = BytesIO(image_bytes)
            image_stream.name = f"{image_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"
            logging.info(f"åœ–ç‰‡å·²æˆåŠŸç”Ÿæˆä¸¦åŒ…è£ç‚º BytesIO ç‰©ä»¶ã€‚")
            return image_stream

        else:
            logging.warning("Gradio Client æœªèƒ½è¿”å›æœ‰æ•ˆçš„åœ–ç‰‡æ•¸æ“šåˆ—è¡¨ã€‚")
            logging.warning(f"å®Œæ•´çµæœ: {result}")
            return None

    except asyncio.TimeoutError:
        logging.error("Gradio Client è«‹æ±‚è¶…æ™‚ã€‚Hugging Face Space å¯èƒ½å¤ªå¿™æˆ–ä»»å‹™å¤ªè¤‡é›œã€‚")
        return None
    except Exception as e:
        logging.error(f"ä½¿ç”¨ Gradio Client ç”Ÿæˆåœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{type(e).__name__}: {e}")
        logging.error("å¯èƒ½çš„åŸå› ï¼šHugging Face Space ä¸å¯ç”¨ã€HF Token æ¬Šé™ä¸è¶³ã€æˆ–åƒæ•¸ä¸åŒ¹é…ã€‚")
        return None